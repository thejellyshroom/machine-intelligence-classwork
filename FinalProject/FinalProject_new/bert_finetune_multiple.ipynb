{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb4c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcfc88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca87985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 43410\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 5426\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels', 'id'],\n",
      "        num_rows: 5427\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "emotion_dataset = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
    "print(emotion_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa5c1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train size: 43410\n",
      "Small train size: 10000\n",
      "Original test size: 5427\n",
      "Small test size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Select a larger subset of examples for better training\n",
    "small_train_dataset = emotion_dataset['train'].select(range(10000))\n",
    "small_test_dataset = emotion_dataset['test'].select(range(1000))\n",
    "\n",
    "# Create a new small dataset with the reduced splits\n",
    "small_emotion_dataset = {\n",
    "    'train': small_train_dataset,\n",
    "    'test': small_test_dataset\n",
    "}\n",
    "\n",
    "print(f\"Original train size: {len(emotion_dataset['train'])}\")\n",
    "print(f\"Small train size: {len(small_train_dataset)}\")\n",
    "print(f\"Original test size: {len(emotion_dataset['test'])}\")\n",
    "print(f\"Small test size: {len(small_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe6e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of emotions dataset:\n",
      "{'text': \"My favourite food is anything I didn't have to cook myself.\", 'labels': [27], 'id': 'eebbqej'}\n",
      "Number of labels: 28\n"
     ]
    }
   ],
   "source": [
    "emotions_id2label = {\n",
    "    0: 'admiration',\n",
    "    1: 'amusement',\n",
    "    2: 'anger',\n",
    "    3: 'annoyance',\n",
    "    4: 'approval',\n",
    "    5: 'caring',\n",
    "    6: 'confusion',\n",
    "    7: 'curiosity',\n",
    "    8: 'desire',\n",
    "    9: 'disappointment',\n",
    "    10: 'disapproval',\n",
    "    11: 'disgust',\n",
    "    12: 'embarrassment',\n",
    "    13: 'excitement',\n",
    "    14: 'fear',\n",
    "    15: 'gratitude',\n",
    "    16: 'grief',\n",
    "    17: 'joy',\n",
    "    18: 'love',\n",
    "    19: 'nervousness',\n",
    "    20: 'optimism',\n",
    "    21: 'pride',\n",
    "    22: 'realization',\n",
    "    23: 'relief',\n",
    "    24: 'remorse',\n",
    "    25: 'sadness',\n",
    "    26: 'surprise',\n",
    "    27: 'neutral'  # Last entry (no comma)\n",
    "}\n",
    "\n",
    "emotions_label2id = {v: k for k, v in emotions_id2label.items()}\n",
    "\n",
    "# Print dataset info to verify we understand what we're working with\n",
    "print(\"Sample of emotions dataset:\")\n",
    "print(small_emotion_dataset[\"train\"][0])\n",
    "print(f\"Number of labels: {len(emotions_id2label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d906f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 6979.04 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 38330.05 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'labels', 'id', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# Tokenize the small dataset\n",
    "small_emotions_encoded = {}\n",
    "small_emotions_encoded['train'] = small_emotion_dataset['train'].map(tokenize, batched=True, batch_size=None)\n",
    "small_emotions_encoded['test'] = small_emotion_dataset['test'].map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "print(small_emotions_encoded['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f6d48f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 24505.29 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 24083.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing columns: ['labels']\n",
      "Renaming 'multi_hot_labels' to 'labels'\n",
      "Calculating sample weights...\n",
      "Sample weights calculated.\n",
      "Setting dataset format to TensorFlow\n",
      "Creating tf.data.Dataset objects with sample weights...\n",
      "Datasets created successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "NUM_CLASSES = 28  # Define the number of classes (matches emotions_id2label)\n",
    "\n",
    "def create_multi_hot_labels(example):\n",
    "    \"\"\"Convert the list of labels into a multi-hot encoded vector.\"\"\"\n",
    "    multi_hot_label = np.zeros(NUM_CLASSES, dtype=np.float32)\n",
    "    if 'labels' in example and isinstance(example['labels'], list) and len(example['labels']) > 0:\n",
    "        for label_id in example['labels']:\n",
    "            if isinstance(label_id, int) and 0 <= label_id < NUM_CLASSES:\n",
    "                multi_hot_label[label_id] = 1.0\n",
    "    example['multi_hot_labels'] = multi_hot_label\n",
    "    return example\n",
    "\n",
    "# Apply the conversion to add the new multi-hot label column\n",
    "small_emotions_encoded['train'] = small_emotions_encoded['train'].map(create_multi_hot_labels)\n",
    "small_emotions_encoded['test'] = small_emotions_encoded['test'].map(create_multi_hot_labels)\n",
    "\n",
    "# Remove the original 'labels' column and any leftover 'label_int'\n",
    "columns_to_remove = [col for col in ['label_int', 'labels'] if col in small_emotions_encoded['train'].features]\n",
    "if columns_to_remove:\n",
    "    print(f\"Removing existing columns: {columns_to_remove}\")\n",
    "    small_emotions_encoded['train'] = small_emotions_encoded['train'].remove_columns(columns_to_remove)\n",
    "    small_emotions_encoded['test'] = small_emotions_encoded['test'].remove_columns(columns_to_remove)\n",
    "\n",
    "# Rename the new column 'multi_hot_labels' to 'labels'\n",
    "if 'multi_hot_labels' in small_emotions_encoded['train'].features:\n",
    "    print(\"Renaming 'multi_hot_labels' to 'labels'\")\n",
    "    small_emotions_encoded['train'] = small_emotions_encoded['train'].rename_column('multi_hot_labels', 'labels')\n",
    "if 'multi_hot_labels' in small_emotions_encoded['test'].features:\n",
    "    small_emotions_encoded['test'] = small_emotions_encoded['test'].rename_column('multi_hot_labels', 'labels')\n",
    "\n",
    "# --- Add Sample Weight Calculation ---\n",
    "print(\"Calculating sample weights...\")\n",
    "# Get all multi-hot labels from the training set as a NumPy array\n",
    "train_labels_np = np.array(small_emotions_encoded['train']['labels'])\n",
    "# Count frequency of each label (column-wise sum)\n",
    "label_counts = np.sum(train_labels_np, axis=0)\n",
    "total_samples = len(train_labels_np)\n",
    "\n",
    "# Calculate weight for each class (inverse frequency, smoothed)\n",
    "class_weights_calc = {}\n",
    "for i in range(NUM_CLASSES):\n",
    "    # Avoid division by zero for labels that might not appear in the subset\n",
    "    count = label_counts[i] if label_counts[i] > 0 else 1\n",
    "    class_weights_calc[i] = total_samples / (NUM_CLASSES * count)\n",
    "\n",
    "# Calculate weight for each sample: max weight of its positive labels\n",
    "sample_weights_np = np.zeros(total_samples, dtype=np.float32)\n",
    "for i in range(total_samples):\n",
    "    sample_label_indices = np.where(train_labels_np[i] == 1.0)[0]\n",
    "    if len(sample_label_indices) > 0:\n",
    "        sample_weights_np[i] = max(class_weights_calc[idx] for idx in sample_label_indices)\n",
    "    else:\n",
    "        # Assign a default weight (e.g., 1.0 or average) for samples with no positive labels\n",
    "        sample_weights_np[i] = 1.0\n",
    "print(\"Sample weights calculated.\")\n",
    "# --- End Sample Weight Calculation ---\n",
    "\n",
    "\n",
    "# Set format to tensorflow\n",
    "feature_cols = [\"input_ids\", \"token_type_ids\", \"attention_mask\"]\n",
    "label_col = \"labels\"\n",
    "cols_to_set_format = feature_cols + [label_col]\n",
    "\n",
    "actual_train_cols = list(small_emotions_encoded['train'].features)\n",
    "actual_test_cols = list(small_emotions_encoded['test'].features)\n",
    "final_train_cols = [col for col in cols_to_set_format if col in actual_train_cols]\n",
    "final_test_cols = [col for col in cols_to_set_format if col in actual_test_cols]\n",
    "\n",
    "if all(col in final_train_cols for col in cols_to_set_format) and \\\n",
    "   all(col in final_test_cols for col in cols_to_set_format):\n",
    "    print(\"Setting dataset format to TensorFlow\")\n",
    "    # Don't set format yet, extract numpy arrays first, then create dataset\n",
    "else:\n",
    "     raise ValueError(f\"Error: Could not find all necessary columns. Train has: {actual_train_cols}, Test has: {actual_test_cols}. Needed: {cols_to_set_format}\")\n",
    "\n",
    "\n",
    "# Extract features and labels as numpy arrays before creating dataset\n",
    "train_features_np = {col: np.array(small_emotions_encoded['train'][col]) for col in feature_cols}\n",
    "train_labels_np = np.array(small_emotions_encoded['train']['labels']) # Already have this from weight calc\n",
    "\n",
    "test_features_np = {col: np.array(small_emotions_encoded['test'][col]) for col in feature_cols}\n",
    "test_labels_np = np.array(small_emotions_encoded['test']['labels'])\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "BATCH_SIZE = 32 # Keep batch size reasonable\n",
    "\n",
    "print(\"Creating tf.data.Dataset objects with sample weights...\")\n",
    "# Modify train_dataset to yield (features, labels, sample_weights)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_features_np, train_labels_np, sample_weights_np)\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(len(sample_weights_np)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "\n",
    "# Test dataset remains (features, labels)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_features_np, test_labels_np)\n",
    ")\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) # Add prefetch\n",
    "print(\"Datasets created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e067bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTForClassification(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, bert_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        # Change activation to 'sigmoid' for multi-label classification\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Make sure we handle the case when inputs is a dictionary\n",
    "        outputs = self.bert(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            token_type_ids=inputs['token_type_ids'],\n",
    "            return_dict=True\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        return self.fc(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce5b9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NUM_CLASSES if not defined globally earlier\n",
    "try:\n",
    "    NUM_CLASSES\n",
    "except NameError:\n",
    "    NUM_CLASSES = 28 # Set default if run out of order\n",
    "\n",
    "# Create a shared emotion prediction function for multi-label output\n",
    "def predict_emotion(text, model, threshold=0.5):\n",
    "    \"\"\"Predict multiple emotions for a given text using the provided model and threshold\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    predictions = model(inputs) # Shape: (1, NUM_CLASSES)\n",
    "\n",
    "    # --- Add this line temporarily ---\n",
    "    # print(f\"Raw probabilities for '{text}': {predictions[0].numpy()}\")\n",
    "    # --- End of added line ---\n",
    "\n",
    "    predicted_labels_indices = tf.where(predictions[0] > threshold).numpy().flatten()\n",
    "    predicted_emotions = []\n",
    "    confidences = []\n",
    "    if len(predicted_labels_indices) > 0:\n",
    "        for index in predicted_labels_indices:\n",
    "            predicted_emotions.append(emotions_id2label[index])\n",
    "            confidences.append(float(predictions[0][index]))\n",
    "    else:\n",
    "        # Optional: If no label passes threshold, predict the highest one or 'neutral'\n",
    "        highest_prob_index = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "        predicted_emotions.append(emotions_id2label[highest_prob_index])\n",
    "        confidences.append(float(predictions[0][highest_prob_index]))\n",
    "\n",
    "\n",
    "    return {\n",
    "        'text': text,\n",
    "        'emotions': predicted_emotions,\n",
    "        'confidences': confidences\n",
    "    }\n",
    "\n",
    "# Define test texts to use for both untrained and trained models\n",
    "test_texts = [\n",
    "    \"I'm so happy today!\",\n",
    "    \"This makes me really angry.\",\n",
    "    \"I'm feeling very sad and disappointed.\",\n",
    "    \"That's really interesting, tell me more.\",\n",
    "    \"I am both excited and nervous about the presentation.\", # Example with multiple emotions\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76f343",
   "metadata": {},
   "source": [
    "## Analyze Test Texts with Untrained Model\n",
    "\n",
    "Let's first create and test our model before training to establish a baseline. This will show how the model performs with random weights, which we can compare to the fine-tuned model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87469b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with UNTRAINED model (random weights - multi-label):\n",
      "-------------------------------------------------------------\n",
      "Raw probabilities for 'I'm so happy today!': [0.64240456 0.7607768  0.41271386 0.17730935 0.18901902 0.5629299\n",
      " 0.2589481  0.74051845 0.30491742 0.36972788 0.62420976 0.6385397\n",
      " 0.773479   0.5157682  0.4701345  0.2500274  0.7306917  0.6394449\n",
      " 0.36029348 0.8246309  0.55854404 0.5302149  0.76650345 0.37005234\n",
      " 0.3335643  0.5530919  0.6025893  0.42961365]\n",
      "Text: I'm so happy today!\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.6424045562744141), ('amusement', 0.7607768177986145), ('anger', 0.4127138555049896), ('annoyance', 0.17730934917926788), ('approval', 0.18901902437210083), ('caring', 0.5629299283027649), ('confusion', 0.25894808769226074), ('curiosity', 0.7405184507369995), ('desire', 0.30491742491722107), ('disappointment', 0.36972787976264954), ('disapproval', 0.6242097616195679), ('disgust', 0.6385396718978882), ('embarrassment', 0.7734789848327637), ('excitement', 0.5157681703567505), ('fear', 0.4701344966888428), ('gratitude', 0.2500273883342743), ('grief', 0.73069167137146), ('joy', 0.639444887638092), ('love', 0.3602934777736664), ('nervousness', 0.8246309161186218), ('optimism', 0.5585440397262573), ('pride', 0.5302149057388306), ('realization', 0.7665034532546997), ('relief', 0.3700523376464844), ('remorse', 0.33356431126594543), ('sadness', 0.5530918836593628), ('surprise', 0.6025893092155457), ('neutral', 0.4296136498451233)]\n",
      "\n",
      "Raw probabilities for 'This makes me really angry.': [0.7105702  0.4495927  0.30021673 0.12030686 0.22675344 0.66601413\n",
      " 0.24661225 0.71624833 0.25794938 0.34615096 0.847026   0.515566\n",
      " 0.7549007  0.5098272  0.5870253  0.14359905 0.74130607 0.79984975\n",
      " 0.64645827 0.8397953  0.5237779  0.24103284 0.6996865  0.509712\n",
      " 0.19584928 0.55426836 0.55354303 0.2610282 ]\n",
      "Text: This makes me really angry.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.710570216178894), ('amusement', 0.4495927095413208), ('anger', 0.3002167344093323), ('annoyance', 0.12030685693025589), ('approval', 0.22675344347953796), ('caring', 0.6660141348838806), ('confusion', 0.24661225080490112), ('curiosity', 0.7162483334541321), ('desire', 0.2579493820667267), ('disappointment', 0.3461509644985199), ('disapproval', 0.847025990486145), ('disgust', 0.5155659914016724), ('embarrassment', 0.7549006938934326), ('excitement', 0.509827196598053), ('fear', 0.5870252847671509), ('gratitude', 0.14359904825687408), ('grief', 0.7413060665130615), ('joy', 0.7998497486114502), ('love', 0.6464582681655884), ('nervousness', 0.8397952914237976), ('optimism', 0.5237779021263123), ('pride', 0.24103283882141113), ('realization', 0.6996865272521973), ('relief', 0.5097119808197021), ('remorse', 0.19584928452968597), ('sadness', 0.5542683601379395), ('surprise', 0.5535430312156677), ('neutral', 0.2610282003879547)]\n",
      "\n",
      "Raw probabilities for 'I'm feeling very sad and disappointed.': [0.69302386 0.5497563  0.31268802 0.14394036 0.17792343 0.5694339\n",
      " 0.18059951 0.78020424 0.32472548 0.3470153  0.79235536 0.5568674\n",
      " 0.78668785 0.47127572 0.48803985 0.18490036 0.72877246 0.7233436\n",
      " 0.4803924  0.81477314 0.5063062  0.3732838  0.732281   0.41234818\n",
      " 0.27347484 0.63971823 0.6020157  0.38929844]\n",
      "Text: I'm feeling very sad and disappointed.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.6930238604545593), ('amusement', 0.5497562885284424), ('anger', 0.31268802285194397), ('annoyance', 0.14394035935401917), ('approval', 0.17792342603206635), ('caring', 0.5694339275360107), ('confusion', 0.18059951066970825), ('curiosity', 0.7802042365074158), ('desire', 0.324725478887558), ('disappointment', 0.34701529145240784), ('disapproval', 0.7923553586006165), ('disgust', 0.5568674206733704), ('embarrassment', 0.7866878509521484), ('excitement', 0.4712757170200348), ('fear', 0.48803985118865967), ('gratitude', 0.18490035831928253), ('grief', 0.7287724614143372), ('joy', 0.7233436107635498), ('love', 0.4803923964500427), ('nervousness', 0.8147731423377991), ('optimism', 0.5063061714172363), ('pride', 0.3732838034629822), ('realization', 0.7322810292243958), ('relief', 0.4123481810092926), ('remorse', 0.2734748423099518), ('sadness', 0.639718234539032), ('surprise', 0.6020156741142273), ('neutral', 0.3892984390258789)]\n",
      "\n",
      "Raw probabilities for 'That's really interesting, tell me more.': [0.6673931  0.68322885 0.39065474 0.17721848 0.20334406 0.5678425\n",
      " 0.24359901 0.68713826 0.2411537  0.4063151  0.74501145 0.6537101\n",
      " 0.742376   0.5087035  0.54594463 0.20996797 0.7202012  0.68980867\n",
      " 0.44109362 0.88491803 0.4915155  0.41533867 0.74841344 0.42702708\n",
      " 0.28181228 0.60828257 0.54636323 0.43637398]\n",
      "Text: That's really interesting, tell me more.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.6673930883407593), ('amusement', 0.6832288503646851), ('anger', 0.3906547427177429), ('annoyance', 0.1772184818983078), ('approval', 0.20334406197071075), ('caring', 0.5678424835205078), ('confusion', 0.24359901249408722), ('curiosity', 0.6871382594108582), ('desire', 0.24115370213985443), ('disappointment', 0.4063150882720947), ('disapproval', 0.7450114488601685), ('disgust', 0.653710126876831), ('embarrassment', 0.7423760294914246), ('excitement', 0.5087034702301025), ('fear', 0.5459446310997009), ('gratitude', 0.2099679708480835), ('grief', 0.7202011942863464), ('joy', 0.6898086667060852), ('love', 0.4410936236381531), ('nervousness', 0.8849180340766907), ('optimism', 0.49151548743247986), ('pride', 0.4153386652469635), ('realization', 0.7484134435653687), ('relief', 0.4270270764827728), ('remorse', 0.28181228041648865), ('sadness', 0.6082825660705566), ('surprise', 0.5463632345199585), ('neutral', 0.4363739788532257)]\n",
      "\n",
      "Raw probabilities for 'I am both excited and nervous about the presentation.': [0.70417804 0.5417714  0.35355198 0.12004349 0.15688144 0.60557324\n",
      " 0.20196846 0.79114014 0.37523136 0.3252459  0.78376293 0.5220251\n",
      " 0.7642598  0.4508476  0.45240316 0.20666341 0.76410455 0.76305735\n",
      " 0.5087837  0.7735311  0.5146118  0.41281584 0.7219109  0.36448473\n",
      " 0.26890585 0.6005785  0.60714704 0.33757466]\n",
      "Text: I am both excited and nervous about the presentation.\n",
      "Predicted emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n",
      "Confidences: [('admiration', 0.7041780352592468), ('amusement', 0.541771411895752), ('anger', 0.353551983833313), ('annoyance', 0.12004348635673523), ('approval', 0.1568814367055893), ('caring', 0.6055732369422913), ('confusion', 0.2019684612751007), ('curiosity', 0.7911401391029358), ('desire', 0.3752313554286957), ('disappointment', 0.3252458870410919), ('disapproval', 0.7837629318237305), ('disgust', 0.5220251083374023), ('embarrassment', 0.7642598152160645), ('excitement', 0.4508475959300995), ('fear', 0.45240315794944763), ('gratitude', 0.20666341483592987), ('grief', 0.7641045451164246), ('joy', 0.7630573511123657), ('love', 0.5087836980819702), ('nervousness', 0.7735310792922974), ('optimism', 0.5146117806434631), ('pride', 0.4128158390522003), ('realization', 0.7219108939170837), ('relief', 0.3644847273826599), ('remorse', 0.2689058482646942), ('sadness', 0.6005784869194031), ('surprise', 0.6071470379829407), ('neutral', 0.33757466077804565)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an untrained model for baseline comparison\n",
    "# Ensure the base model 'model' is loaded correctly from cell 2\n",
    "untrained_classifier = BERTForClassification(model, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Compile the model for multi-label classification\n",
    "untrained_classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=2e-5),\n",
    "    # Use BinaryCrossentropy for multi-label with sigmoid activation\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    # Use BinaryAccuracy for multi-label evaluation\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "print(\"Predictions with UNTRAINED model (random weights - multi-label):\")\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "# Get predictions from untrained model using our updated shared function\n",
    "for text in test_texts:\n",
    "    result = predict_emotion(text, untrained_classifier, threshold=0.1) # Lower threshold for untrained might show more random outputs\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Predicted emotions: {result['emotions']}\")\n",
    "    # Zip confidences with emotions for clarity\n",
    "    emotion_confidence_pairs = list(zip(result['emotions'], result['confidences']))\n",
    "    print(f\"Confidences: {emotion_confidence_pairs}\")\n",
    "    # print(f\"Confidences: {[f'{c:.4f}' for c in result['confidences']]}\")\n",
    "    print()\n",
    "\n",
    "# Evaluating accuracy on the test set for an untrained multi-label model isn't very informative\n",
    "# untrained_loss, untrained_accuracy = untrained_classifier.evaluate(test_dataset, verbose=0)\n",
    "# print(f\"Untrained model test accuracy (BinaryAccuracy): {untrained_accuracy:.4f}\")\n",
    "# Random baseline for BinaryAccuracy depends on label distribution, harder to interpret than single-label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d127d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model with AUC, Precision, Recall...\n",
      "Model compiled.\n"
     ]
    }
   ],
   "source": [
    "# --- Suggested Change for Cell ID: d127d7b4 ---\n",
    "\n",
    "# Update num_classes if not already defined\n",
    "try:\n",
    "    NUM_CLASSES\n",
    "except NameError:\n",
    "    NUM_CLASSES = 28\n",
    "\n",
    "# Define the model - ensure 'model' (the base BERT model) is loaded\n",
    "classifier = BERTForClassification(model, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Compile the model for multi-label classification with more metrics\n",
    "print(\"Compiling model with AUC, Precision, Recall...\")\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=2e-5), # Consider trying AdamW later\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), # Correct loss for multi-label sigmoid\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.AUC(multi_label=True, name='auc'), # Good overall multi-label metric\n",
    "        tf.keras.metrics.Precision(name='precision'), # How many selected items are relevant?\n",
    "        tf.keras.metrics.Recall(name='recall') # How many relevant items are selected?\n",
    "        ]\n",
    ")\n",
    "print(\"Model compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9df6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multi-label model training with sample weights...\n",
      "Epoch 1/5\n",
      "313/313 [==============================] - 720s 2s/step - loss: 0.1865 - accuracy: 0.9510 - auc: 0.5882 - precision: 0.0749 - recall: 0.0141 - val_loss: 0.1423 - val_accuracy: 0.9610 - val_auc: 0.7653 - val_precision: 0.9571 - val_recall: 0.0579\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 741s 2s/step - loss: 0.1367 - accuracy: 0.9604 - auc: 0.8260 - precision: 0.8304 - recall: 0.0787 - val_loss: 0.1210 - val_accuracy: 0.9631 - val_auc: 0.8775 - val_precision: 0.7541 - val_recall: 0.1590\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 713s 2s/step - loss: 0.1108 - accuracy: 0.9633 - auc: 0.8965 - precision: 0.7561 - recall: 0.1926 - val_loss: 0.1120 - val_accuracy: 0.9642 - val_auc: 0.8926 - val_precision: 0.7273 - val_recall: 0.2143\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 731s 2s/step - loss: 0.0905 - accuracy: 0.9652 - auc: 0.9333 - precision: 0.7311 - recall: 0.2792 - val_loss: 0.1090 - val_accuracy: 0.9641 - val_auc: 0.9009 - val_precision: 0.6396 - val_recall: 0.2990\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 734s 2s/step - loss: 0.0773 - accuracy: 0.9676 - auc: 0.9498 - precision: 0.7283 - recall: 0.3700 - val_loss: 0.1068 - val_accuracy: 0.9629 - val_auc: 0.9099 - val_precision: 0.5896 - val_recall: 0.3328\n",
      "Training finished.\n",
      "Evaluating model on test set...\n",
      "32/32 [==============================] - 22s 684ms/step - loss: 0.1068 - accuracy: 0.9629 - auc: 0.9099 - precision: 0.5896 - recall: 0.3328\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "- loss: 0.1068\n",
      "- accuracy: 0.9629\n",
      "- auc: 0.9099\n",
      "- precision: 0.5896\n",
      "- recall: 0.3328\n"
     ]
    }
   ],
   "source": [
    "# --- Suggested Change for Cell ID: e9df6074 ---\n",
    "\n",
    "# Train the model\n",
    "# Sample weights are now included in train_dataset, so no class_weight argument needed\n",
    "# Ensure train_dataset and test_dataset are correctly defined from the previous cell\n",
    "\n",
    "print(\"Starting multi-label model training with sample weights...\")\n",
    "# Consider adding callbacks like EarlyStopping or ModelCheckpoint for longer runs\n",
    "# callbacks = [\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=3, mode='max', restore_best_weights=True),\n",
    "#     tf.keras.callbacks.ModelCheckpoint('best_emotion_model.keras', save_best_only=True, monitor='val_auc', mode='max')\n",
    "# ]\n",
    "\n",
    "history = classifier.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,  # Adjust epochs as needed, more data might require more/fewer epochs\n",
    "    validation_data=test_dataset\n",
    "    # callbacks=callbacks # Uncomment to use callbacks\n",
    ")\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "results = classifier.evaluate(test_dataset, verbose=1) # Use verbose=1 to see progress\n",
    "\n",
    "# Print evaluation results dynamically based on compiled metrics\n",
    "print(\"\\nTest Set Evaluation Results:\")\n",
    "for name, value in zip(classifier.metrics_names, results):\n",
    "    print(f\"- {name}: {value:.4f}\")\n",
    "\n",
    "# Example: Accessing specific metrics if needed\n",
    "# test_loss = results[classifier.metrics_names.index('loss')]\n",
    "# test_auc = results[classifier.metrics_names.index('auc')]\n",
    "# print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f61dbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions with TRAINED multi-label model:\n",
      "----------------------------------------\n",
      "Text: I'm so happy today!\n",
      "Predicted emotions: ['excitement', 'joy']\n",
      "Confidences: [('excitement', 0.12582339346408844), ('joy', 0.7270192503929138)]\n",
      "\n",
      "Text: This makes me really angry.\n",
      "Predicted emotions: ['anger', 'annoyance']\n",
      "Confidences: [('anger', 0.702703595161438), ('annoyance', 0.11748744547367096)]\n",
      "\n",
      "Text: I'm feeling very sad and disappointed.\n",
      "Predicted emotions: ['disappointment', 'grief', 'sadness']\n",
      "Confidences: [('disappointment', 0.3193146586418152), ('grief', 0.1527215540409088), ('sadness', 0.8931897878646851)]\n",
      "\n",
      "Text: That's really interesting, tell me more.\n",
      "Predicted emotions: ['excitement', 'joy']\n",
      "Confidences: [('excitement', 0.731715202331543), ('joy', 0.12100547552108765)]\n",
      "\n",
      "Text: I am both excited and nervous about the presentation.\n",
      "Predicted emotions: ['fear', 'nervousness']\n",
      "Confidences: [('fear', 0.31013643741607666), ('nervousness', 0.45450836420059204)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions with TRAINED multi-label model:\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "# Use the updated shared function with the trained model\n",
    "prediction_threshold = 0.1 # Adjust threshold as needed based on validation performance\n",
    "\n",
    "for text in test_texts:\n",
    "    result = predict_emotion(text, classifier, threshold=prediction_threshold)\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Predicted emotions: {result['emotions']}\")\n",
    "    # Zip confidences with emotions for clarity\n",
    "    emotion_confidence_pairs = list(zip(result['emotions'], result['confidences']))\n",
    "    print(f\"Confidences: {emotion_confidence_pairs}\")\n",
    "    # print(f\"Confidences: {[f'{c:.4f}' for c in result['confidences']]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
